{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa128b2",
   "metadata": {},
   "source": [
    "# Assignment 2 Lab\n",
    "## Cost Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc53ec0",
   "metadata": {},
   "source": [
    "## Spring 2024 (February 22, 2024)\n",
    "## DSSA5104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e9f53-6936-407f-b598-42922f5b7ed0",
   "metadata": {},
   "source": [
    "### <font color='blue'> Instructions</font>\n",
    "Here is another Jupyter Notebook to work with Cost (or Loss) functions. However, I have not completed all the code. Please complete the code so that it works, and also answer the question at the bottom of the notebook.\n",
    "\n",
    "I hope this assignment will not be too difficult for anyone. So study what it is doing so that you really understand why we use these cost functions.\n",
    "\n",
    "For additional information, see pp.64-73 of our textbook Make Your Own Neural Network (2016) by Tariq Rashid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15874bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required Python Libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92fb2f",
   "metadata": {},
   "source": [
    "This notebook is an initial examination of cost functions. A cost function can be any function that outputs a scalar that quantifies the error of your neural networkâ€™s performance.\n",
    "\n",
    "Say we have output data of the expected results and actual results from a Neural Network. \n",
    "Although we should probably read it in as a Pandas dataframe, for this example we will just use a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d43214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = np.random.normal(size = (100,2))\n",
    "np.savetxt(\"assignment3.csv\", loss, delimiter=\",\", fmt='%1.3f')\n",
    "loss = np.loadtxt(\"assignment3.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae8b97",
   "metadata": {},
   "source": [
    "We know that the first column are the expected results, and the second column are the actual results. Remember that Python is zero-based. So column 0 is expected and column 1 is actual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d656b",
   "metadata": {},
   "source": [
    "At a basic level, we want to know the difference between the expected results and the actual results. We can compute the sum of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1d6944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.999000000000002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(loss[:,0] - loss[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754fd0fa",
   "metadata": {},
   "source": [
    "And then we can take the average to get the average difference across all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e41fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12999000000000002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(loss[:,0] - loss[:,1]) / loss[:,0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336336aa",
   "metadata": {},
   "source": [
    "We could save the result as the average of the differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729d06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = loss[:,0].size\n",
    "avgDiff = sum(loss[:,0] - loss[:,1]) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3893694",
   "metadata": {},
   "source": [
    "That looks really good, except for the fact that the negatives are canceling out the positive errors! If we look at the data (print(loss)), we can see that most actual values are off much more than our avgDiff metric!\n",
    "\n",
    "We need a better metric for the loss (or cost). We need a cost function that can be written as a function of the outputs from the neural network, and we will assume our cost functions meet that assumption. \n",
    "\n",
    "Since we are going to be working with these two columns of data, let us make it easy on ourselves and set them to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db486cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = loss[:,0]\n",
    "actual = loss[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488a4df",
   "metadata": {},
   "source": [
    "We know there are plenty of cost functions, and we reviewed four of them in class. The Mean Squared Error (MSE), the Standard Error (SE), the Root Mean Square error (RMS), and the Sum of Squared Errors (SSE). Refer to the class slides (or any reference you like) and compute the MSE, SE, RMS, and SSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd03428-ada9-442b-8bad-a2656c341b8a",
   "metadata": {},
   "source": [
    "## <font color='red'>1. Complete the code in the following block</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aeb87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184.986223\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sum of Squared Errors  (SSE)\n",
    "sse = np.sum((expected - actual) ** 2)\n",
    "\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774d29f-ff6a-48fb-8499-621195d54b62",
   "metadata": {},
   "source": [
    "## <font color='red'>2. Complete the code in the following block</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554296da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5521600e-01 2.3531560e+00 4.2890410e+00 2.9790760e+00 1.3018810e+00\n",
      " 6.0840000e-01 6.2900640e+00 5.4009760e+00 4.9996960e+00 2.1874410e+00\n",
      " 3.1258240e+00 7.4310760e+00 6.4211560e+00 8.4640000e-03 8.4100000e-04\n",
      " 4.3305610e+00 1.1470410e+00 2.3901160e+00 6.2001000e-02 5.5204900e-01\n",
      " 4.0481440e+00 8.6490000e-03 7.7841000e-02 2.0707210e+00 4.8441600e-01\n",
      " 4.2477210e+00 3.0695040e+00 8.6436000e-02 2.9584000e-02 1.5523600e-01\n",
      " 1.7472400e-01 1.0506250e+00 2.0649690e+00 1.9713600e-01 1.2950440e+00\n",
      " 1.0342890e+00 6.8890000e-03 1.8062500e-01 7.6562500e-01 2.5122250e+00\n",
      " 3.3635560e+00 3.0250000e-03 1.2321000e+00 1.4884000e-02 3.4819560e+00\n",
      " 9.3508900e-01 1.9009600e-01 9.1445760e+00 3.1116960e+00 1.9154560e+00\n",
      " 1.2210250e+00 4.4478810e+00 3.9402250e+00 1.5202890e+00 1.4280250e+00\n",
      " 8.3356900e-01 2.6308840e+00 5.5979560e+00 1.8748900e-01 8.2810000e-03\n",
      " 7.1289000e-02 5.2900000e-04 1.2744900e-01 2.6896000e-02 9.5452900e-01\n",
      " 8.7025000e-02 1.6563690e+00 6.8392900e-01 7.0756000e-02 8.5008400e-01\n",
      " 8.1902500e-01 2.3425600e-01 4.9996960e+00 2.4964000e+00 2.2090000e-03\n",
      " 4.6010250e+00 2.7144100e-01 4.2120100e-01 3.0976000e-02 2.4711840e+00\n",
      " 9.3513640e+00 8.7048900e-01 1.8414490e+00 3.3640000e-03 1.9237690e+00\n",
      " 4.3560000e-01 9.0250000e-03 3.3196840e+00 5.6453760e+00 1.1155600e-01\n",
      " 2.3716900e-01 4.0000000e-04 2.3040000e-03 8.8209000e-02 2.1609000e-02\n",
      " 6.4802500e-01 1.5750250e+00 7.6387600e-01 4.4100000e-02 1.2215025e+01]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Squared Error (SE)\n",
    "se = (expected - actual) ** 2\n",
    "\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebe12f-1e1f-4b53-be9b-ef421495588f",
   "metadata": {},
   "source": [
    "## <font color='red'>3. Complete the code in the following block</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e4222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.84986223\n"
     ]
    }
   ],
   "source": [
    "# Calculate Squared Error (SE)\n",
    "se = (expected - actual) ** 2\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = np.mean(se)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b59d5b-f3e1-4e77-b183-95c330a34bea",
   "metadata": {},
   "source": [
    "## <font color='red'>4. Complete the code in the following block</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d92e8f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3600964046713748\n"
     ]
    }
   ],
   "source": [
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2fd38",
   "metadata": {},
   "source": [
    "While these are the most popular, there is no scientific way to determine what cost function is the best (although some may be inappropriate for your use). It is more trial and error to find the one you like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3986d",
   "metadata": {},
   "source": [
    "Depending on your data and model, there are many other cost functions available (e.g. Cross-Entropy, Exponential, Hellinger Distance, Kullback-Leibler Divergence). See https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications. Personally I have mainly used the four common ones computed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41557a6",
   "metadata": {},
   "source": [
    "## <font color='red'>5. Question</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f57a4",
   "metadata": {},
   "source": [
    "Write a one-paragraph explanation of why we need a cost (or loss) function at all. You can insert your paragraph into this Notebook or attach it separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd155aa5-8ab3-4ed1-9edb-d8424784bd23",
   "metadata": {},
   "source": [
    "A cost or loss function is essential in various machine learning and optimization tasks as it serves as a quantitative measure of how well a model is performing concerning its predictions compared to the ground truth or actual values. By quantifying the disparity between predicted and actual outcomes, the cost function provides a clear objective for the model to minimize during training. This optimization objective guides the iterative process of adjusting model parameters to improve performance, ultimately leading to better generalization and predictive capability. Without a cost function, it would be challenging to evaluate model performance systematically and effectively guide the learning process towards optimal solutions, hindering the model's ability to learn and make accurate predictions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
